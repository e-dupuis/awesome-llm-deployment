# awesome-llm-deployment
Deploying LLM models is proven to be a challenging task in constrained environment, here is a collection of resources that can help.
This is a continuous work in progress and both the structure and the content will be improved over time. Any PR or comment is more than welcome.

# Inference Optimisation Techniques
- [ExLLAMAv2](https://github.com/turboderp/exllamav2) - Framework to expore different quantization levels for LLM and their impact on the accuracy and the runtime.

# Model Serving/ Inference Engine
- [vLLM](https://github.com/vllm-project/vllm) - vLLM is a fast and easy-to-use library for LLM inference and serving.
- [LangChain](https://python.langchain.com/docs/get_started/introduction) - is a framework for developing applications powered by language models (Python)

# Learning Material
- [DataScience-StudyMaterial](https://github.com/deshwalmahesh/DataScience-StudyMaterial/tree/main) - resources to study LLM & ML, with annotated papers

