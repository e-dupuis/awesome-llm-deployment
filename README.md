# awesome-llm-deployment
Deploying LLM models is proven to be a challenging task in constrained environment, here is a collection of resources that can help.
This is a continuous work in progress and both the structure and the content will be improved over time. Any PR or comment is more than welcome.

# Inference Optimisation Techniques
- [ExLLAMAv2](https://github.com/turboderp/exllamav2) - Framework to expore different quantization levels for LLM and their impact on the accuracy and the runtime.

# Model Serving/ Inference Engine
- [vLLM](https://github.com/vllm-project/vllm) - vLLM is a fast and easy-to-use library for LLM inference and serving.
- [LangChain](https://python.langchain.com/docs/get_started/introduction) - is a framework for developing applications powered by language models (Python).

# Learning Material
- [DataScience-StudyMaterial](https://github.com/deshwalmahesh/DataScience-StudyMaterial/tree/main) - resources to study LLM & ML, with annotated papers.

# Benchmark
- [Hugging Face LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) - The HF Open LLM Leaderboard aims to track, rank and evaluate open LLMs and chatbots.
- [Hugging Face LLM Perf Leaderboard](https://huggingface.co/spaces/optimum/llm-perf-leaderboard) - aims to benchmark the performance (latency, throughput, memory & energy) of Large Language Models (LLMs) with different hardwares, backends and optimizations.
- [Can it run LLM?](https://huggingface.co/spaces/Vokturz/can-it-run-llm) - A tool designed to comprehensively analyze the hardware requirements necessary for the execution of a specific LLM.

# Open Models
- [Hugging Face LLMs](https://huggingface.co/models?other=LLM) - list of models from HF.
- [GPT4All](https://gpt4all.io/index.html) - a free-to-use, locally running, privacy-aware chatbot. No GPU or internet required.
- [ExploreLLM](https://llm.extractum.io) - Explore and compare the LLMs that fit your needs.

